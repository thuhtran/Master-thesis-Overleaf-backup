{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries/Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import pandas as pd\n",
    "\n",
    "#merging parquet files\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_parquet(ext, depth, org_path):\n",
    "    patterns = []\n",
    "    for d in range(depth + 1):\n",
    "        pattern = os.path.join(org_path, *(['*'] * d), f\"*.{ext}\") #keyword: glob/wild-card\n",
    "        patterns.append(pattern)\n",
    "    \n",
    "    file_paths = []\n",
    "    for pattern in patterns:\n",
    "        file_paths.extend(glob.glob(pattern))\n",
    "    \n",
    "    file_paths = [fp for fp in file_paths if '/N/' in fp.replace(os.sep, '/')] #NYSE only\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IBM/JPM/PFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_path = \"/Users/carrot2506/Files on Lap/Thesis Preparation/Data/IBM/2002\" #search path\n",
    "search_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Date   Time   Price  Volume\n",
      "0  20020102  34215  120.60  172900\n",
      "1  20020102  34218  120.60    1500\n",
      "2  20020102  34221  120.60   20000\n",
      "3  20020102  34227  120.61    1200\n",
      "4  20020102  34233  120.51    1000\n",
      "            Date   Time  Price  Volume\n",
      "877658  20021231  57587  77.54    6000\n",
      "877659  20021231  57588  77.54     100\n",
      "877660  20021231  57589  77.55    2300\n",
      "877661  20021231  57594  77.54    5700\n",
      "877662  20021231  57595  77.55    3200\n"
     ]
    }
   ],
   "source": [
    "trade_files = merge_parquet(\"parquet\", search_depth, org_path)\n",
    "trade_files = [f for f in trade_files if \"trades\" in f]\n",
    "\n",
    "dfs = [pd.read_parquet(f) for f in trade_files]\n",
    "merged_trade_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_trade_data.sort_values(by=[\"Date\", \"Time\"], inplace=True)\n",
    "merged_trade_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_file = os.path.join(os.getcwd(), \"merged_trade_IBM_N_2002_Thu.parquet\")\n",
    "merged_trade_data.to_parquet(output_file)\n",
    "\n",
    "merged_df = pd.read_parquet(output_file)\n",
    "print(merged_df.head(5))\n",
    "print(merged_df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Date   Time    Bid  Bidvol     Ask  Askvol\n",
      "0  20020102  34223  120.6       1  120.61      27\n",
      "1  20020102  34227  120.6       1  120.61      39\n",
      "2  20020102  34229  120.5       1  120.61      39\n",
      "3  20020102  34234  120.5      29  120.61      39\n",
      "4  20020102  34237  120.5      29  120.51       1\n",
      "             Date   Time    Bid  Bidvol    Ask  Askvol\n",
      "1672080  20021231  57571  77.45       1  77.59       1\n",
      "1672081  20021231  57577  77.45       1  77.59       1\n",
      "1672082  20021231  57589  77.52       2  77.55      26\n",
      "1672083  20021231  57592  77.52       2  77.55      26\n",
      "1672084  20021231  57599  77.52       2  77.59      26\n"
     ]
    }
   ],
   "source": [
    "quote_files = merge_parquet(\"parquet\", search_depth, org_path)\n",
    "quote_files = [f for f in quote_files if \"quotes\" in f]\n",
    "\n",
    "dfs_q = [pd.read_parquet(f) for f in quote_files]\n",
    "merged_quote_data = pd.concat(dfs_q, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_quote_data.sort_values(by=[\"Date\", \"Time\"], inplace=True)\n",
    "merged_quote_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_file_q = os.path.join(os.getcwd(), \"merged_quote_IBM_N_2002_Thu.parquet\")\n",
    "merged_quote_data.to_parquet(output_file_q)\n",
    "\n",
    "merged_df_q = pd.read_parquet(output_file_q)\n",
    "print(merged_df_q.head(5))\n",
    "print(merged_df_q.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### March 2020 - Covid 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_path = \"/Users/carrot2506/Files on Lap/Thesis Preparation/Data/Pfizer/2020/3\" #search path\n",
    "search_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_files = merge_parquet(\"parquet\", search_depth, org_path)\n",
    "trade_files = [f for f in trade_files if \"trades\" in f]\n",
    "\n",
    "dfs = [pd.read_parquet(f) for f in trade_files]\n",
    "merged_trade_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_trade_data.sort_values(by=[\"Date\", \"Time\"], inplace=True)\n",
    "merged_trade_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_file = os.path.join(os.getcwd(), \"merged_trade_PFE_N_2020_Mar_Thu.parquet\")\n",
    "merged_trade_data.to_parquet(output_file)\n",
    "\n",
    "merged_df = pd.read_parquet(output_file)\n",
    "print(merged_df.head(5))\n",
    "print(merged_df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_files = merge_parquet(\"parquet\", search_depth, org_path)\n",
    "quote_files = [f for f in quote_files if \"quotes\" in f]\n",
    "\n",
    "dfs_q = [pd.read_parquet(f) for f in quote_files]\n",
    "merged_quote_data = pd.concat(dfs_q, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_quote_data.sort_values(by=[\"Date\", \"Time\"], inplace=True)\n",
    "merged_quote_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_file_q = os.path.join(os.getcwd(), \"merged_quote_PFE_N_2020_Mar_Thu.parquet\")\n",
    "merged_quote_data.to_parquet(output_file_q)\n",
    "\n",
    "merged_df_q = pd.read_parquet(output_file_q)\n",
    "print(merged_df_q.head(5))\n",
    "print(merged_df_q.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sep/Oct 2008 Lehman Brothers collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_path = \"/Users/carrot2506/Files on Lap/Thesis Preparation/Data/Pfizer/2008\" #search path\n",
    "search_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_files = merge_parquet(\"parquet\", search_depth, org_path)\n",
    "\n",
    "trade_files = [\n",
    "    f for f in trade_files\n",
    "    if \"/2008/9/\" in f.replace(os.sep, '/') or \"/2008/10/\" in f.replace(os.sep, '/')]\n",
    "trade_files = [f for f in trade_files if \"trades\" in f]\n",
    "\n",
    "dfs = [pd.read_parquet(f) for f in trade_files]\n",
    "merged_trade_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_trade_data.sort_values(by=[\"Date\", \"Time\"], inplace=True)\n",
    "merged_trade_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_file = os.path.join(os.getcwd(), \"merged_trade_PFE_N_2008_Sep_Oct_Thu.parquet\")\n",
    "merged_trade_data.to_parquet(output_file)\n",
    "\n",
    "merged_df = pd.read_parquet(output_file)\n",
    "print(merged_df.head(5))\n",
    "print(merged_df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_files = merge_parquet(\"parquet\", search_depth, org_path)\n",
    "\n",
    "quote_files = [\n",
    "    f for f in quote_files\n",
    "    if \"/2008/9/\" in f.replace(os.sep, '/') or \"/2008/10/\" in f.replace(os.sep, '/')]\n",
    "quote_files = [f for f in quote_files if \"quotes\" in f]\n",
    "\n",
    "dfs_q = [pd.read_parquet(f) for f in quote_files]\n",
    "merged_quote_data = pd.concat(dfs_q, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_quote_data.sort_values(by=[\"Date\", \"Time\"], inplace=True)\n",
    "merged_quote_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_file_q = os.path.join(os.getcwd(), \"merged_quote_PFE_N_2008_Sep_Oct_Thu.parquet\")\n",
    "merged_quote_data.to_parquet(output_file_q)\n",
    "\n",
    "merged_df_q = pd.read_parquet(output_file_q)\n",
    "print(merged_df_q.head(5))\n",
    "print(merged_df_q.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jan 2023 - To test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_path = \"/Users/carrot2506/Files on Lap/Thesis Preparation/Data/JPM/2023/1\" #search path\n",
    "search_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_files = merge_parquet(\"parquet\", search_depth, org_path)\n",
    "trade_files = [f for f in trade_files if \"trades\" in f]\n",
    "\n",
    "dfs = [pd.read_parquet(f) for f in trade_files]\n",
    "merged_trade_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_trade_data.sort_values(by=[\"Date\", \"Time\"], inplace=True)\n",
    "merged_trade_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_file = os.path.join(os.getcwd(), \"merged_trade_JPM_N_2023_Jan_Thu.parquet\")\n",
    "merged_trade_data.to_parquet(output_file)\n",
    "\n",
    "merged_df = pd.read_parquet(output_file)\n",
    "print(merged_df.head(5))\n",
    "print(merged_df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_files = merge_parquet(\"parquet\", search_depth, org_path)\n",
    "quote_files = [f for f in quote_files if \"quotes\" in f]\n",
    "\n",
    "dfs_q = [pd.read_parquet(f) for f in quote_files]\n",
    "merged_quote_data = pd.concat(dfs_q, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_quote_data.sort_values(by=[\"Date\", \"Time\"], inplace=True)\n",
    "merged_quote_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_file_q = os.path.join(os.getcwd(), \"merged_quote_JPM_N_2023_Jan_Thu.parquet\")\n",
    "merged_quote_data.to_parquet(output_file_q)\n",
    "\n",
    "merged_df_q = pd.read_parquet(output_file_q)\n",
    "print(merged_df_q.head(5))\n",
    "print(merged_df_q.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feb-April 2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_path = \"/Users/carrot2506/Files on Lap/Thesis Preparation/Data/IBM/2020\" #search path\n",
    "search_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Date          Time   Price  Volume\n",
      "0  20200203  34241.129055  144.32  171264\n",
      "1  20200203  34241.145687  144.30      22\n",
      "2  20200203  34241.145696  144.27       5\n",
      "3  20200203  34241.145748  144.25      73\n",
      "4  20200203  34241.153160  144.35       4\n",
      "            Date          Time   Price  Volume\n",
      "786993  20200430  57599.924341  125.52     800\n",
      "786994  20200430  57599.996780  125.47     500\n",
      "786995  20200430  57599.996877  125.47    1000\n",
      "786996  20200430  57599.997142  125.47     900\n",
      "786997  20200430  57599.997484  125.47     535\n"
     ]
    }
   ],
   "source": [
    "trade_files = merge_parquet(\"parquet\", search_depth, org_path)\n",
    "\n",
    "trade_files = [\n",
    "    f for f in trade_files\n",
    "    if \"/2020/2/\" in f.replace(os.sep, '/') or \"/2020/3/\" in f.replace(os.sep, '/') or \"/2020/4/\" in f.replace(os.sep, '/')]\n",
    "trade_files = [f for f in trade_files if \"trades\" in f]\n",
    "\n",
    "dfs = [pd.read_parquet(f) for f in trade_files]\n",
    "merged_trade_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_trade_data.sort_values(by=[\"Date\", \"Time\"], inplace=True)\n",
    "merged_trade_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_file = os.path.join(os.getcwd(), \"merged_trade_IBM_N_2020_Feb_Mar_Apr_Thu.parquet\")\n",
    "merged_trade_data.to_parquet(output_file)\n",
    "\n",
    "merged_df = pd.read_parquet(output_file)\n",
    "print(merged_df.head(5))\n",
    "print(merged_df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Date          Time     Bid  Bidvol     Ask  Askvol\n",
      "0  20200203  34241.139310  144.20       1  144.38       1\n",
      "1  20200203  34241.142553  144.25       1  144.38       1\n",
      "2  20200203  34241.142582  144.25       2  144.38       1\n",
      "3  20200203  34241.144191  144.25       1  144.38       1\n",
      "4  20200203  34241.144780  144.25       1  144.38       2\n",
      "             Date          Time     Bid  Bidvol     Ask  Askvol\n",
      "8995326  20200430  57599.996767  125.46     149  125.47      29\n",
      "8995327  20200430  57599.996873  125.46     149  125.47      24\n",
      "8995328  20200430  57599.996974  125.46     149  125.47      14\n",
      "8995329  20200430  57599.997323  125.46     149  125.47       5\n",
      "8995330  20200430  57599.997502  125.46     149  125.52      36\n"
     ]
    }
   ],
   "source": [
    "quote_files = merge_parquet(\"parquet\", search_depth, org_path)\n",
    "\n",
    "quote_files = [\n",
    "    f for f in quote_files\n",
    "    if \"/2020/2/\" in f.replace(os.sep, '/') or \"/2020/3/\" in f.replace(os.sep, '/') or \"/2020/4/\" in f.replace(os.sep, '/')]\n",
    "quote_files = [f for f in quote_files if \"quotes\" in f]\n",
    "\n",
    "dfs_q = [pd.read_parquet(f) for f in quote_files]\n",
    "merged_quote_data = pd.concat(dfs_q, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_quote_data.sort_values(by=[\"Date\", \"Time\"], inplace=True)\n",
    "merged_quote_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_file_q = os.path.join(os.getcwd(), \"merged_quote_IBM_N_2020_Feb_Mar_Apr_Thu.parquet\")\n",
    "merged_quote_data.to_parquet(output_file_q)\n",
    "\n",
    "merged_df_q = pd.read_parquet(output_file_q)\n",
    "print(merged_df_q.head(5))\n",
    "print(merged_df_q.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match TAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = pd.read_parquet(\"/Users/carrot2506/Files on Lap/Thesis Preparation/Data/merged_trade_IBM_N_2020_Feb_Mar_Apr_Thu.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 786998 entries, 0 to 786997\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Date    786998 non-null  int64  \n",
      " 1   Time    786998 non-null  float64\n",
      " 2   Price   786998 non-null  float64\n",
      " 3   Volume  786998 non-null  uint64 \n",
      "dtypes: float64(2), int64(1), uint64(1)\n",
      "memory usage: 24.0 MB\n",
      "None\n",
      "       Date          Time   Price  Volume\n",
      "0  20200203  34241.129055  144.32  171264\n",
      "1  20200203  34241.145687  144.30      22\n",
      "2  20200203  34241.145696  144.27       5\n",
      "3  20200203  34241.145748  144.25      73\n",
      "4  20200203  34241.153160  144.35       4\n"
     ]
    }
   ],
   "source": [
    "print(trade.info())\n",
    "print(trade.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = trade[(trade['Volume'] > 0) & (trade['Price'] > 0)]  #only keep positive trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine datetime\n",
    "trade['datetime'] = pd.to_datetime(trade['Date'].astype(str), format='%Y%m%d')\n",
    "trade['datetime'] += pd.to_timedelta(trade['Time'], unit='s')\n",
    "trade['datetime'] = trade['datetime'].dt.tz_localize('US/Eastern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Quote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote =  pd.read_parquet(\"/Users/carrot2506/Files on Lap/Thesis Preparation/Data/merged_quote_IBM_N_2020_Feb_Mar_Apr_Thu.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8995331 entries, 0 to 8995330\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   Date    int64  \n",
      " 1   Time    float64\n",
      " 2   Bid     float64\n",
      " 3   Bidvol  uint64 \n",
      " 4   Ask     float64\n",
      " 5   Askvol  uint64 \n",
      "dtypes: float64(3), int64(1), uint64(2)\n",
      "memory usage: 411.8 MB\n",
      "None\n",
      "       Date          Time     Bid  Bidvol     Ask  Askvol\n",
      "0  20200203  34241.139310  144.20       1  144.38       1\n",
      "1  20200203  34241.142553  144.25       1  144.38       1\n",
      "2  20200203  34241.142582  144.25       2  144.38       1\n",
      "3  20200203  34241.144191  144.25       1  144.38       1\n",
      "4  20200203  34241.144780  144.25       1  144.38       2\n"
     ]
    }
   ],
   "source": [
    "print(quote.info())\n",
    "print(quote.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = quote[(quote['Bid'] > 0) & (quote['Bidvol'] > 0) & (quote['Askvol'] > 0) & (quote['Ask'] > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine datetime\n",
    "quote['datetime'] = pd.to_datetime(quote['Date'].astype(str), format='%Y%m%d')\n",
    "quote['datetime'] += pd.to_timedelta(quote['Time'], unit='s')\n",
    "quote['datetime'] = quote['datetime'].dt.tz_localize('US/Eastern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchTQ_backward = pd.merge_asof(\n",
    "    trade, quote, by=\"Date\", on=\"datetime\", direction=\"backward\") #match trades with the closest prevailing quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date        Time_x   Price  Volume  \\\n",
      "786993  20200430  57599.924341  125.52     800   \n",
      "786994  20200430  57599.996780  125.47     500   \n",
      "786995  20200430  57599.996877  125.47    1000   \n",
      "786996  20200430  57599.997142  125.47     900   \n",
      "786997  20200430  57599.997484  125.47     535   \n",
      "\n",
      "                                  datetime        Time_y     Bid  Bidvol  \\\n",
      "786993 2020-04-30 15:59:59.924340994-04:00  57599.922019  125.44   446.0   \n",
      "786994 2020-04-30 15:59:59.996780250-04:00  57599.996767  125.46   149.0   \n",
      "786995 2020-04-30 15:59:59.996877023-04:00  57599.996873  125.46   149.0   \n",
      "786996 2020-04-30 15:59:59.997141769-04:00  57599.996974  125.46   149.0   \n",
      "786997 2020-04-30 15:59:59.997483893-04:00  57599.997323  125.46   149.0   \n",
      "\n",
      "           Ask  Askvol  \n",
      "786993  125.52    22.0  \n",
      "786994  125.47    29.0  \n",
      "786995  125.47    24.0  \n",
      "786996  125.47    14.0  \n",
      "786997  125.47     5.0  \n"
     ]
    }
   ],
   "source": [
    "print(matchTQ_backward.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchTQ_backward = matchTQ_backward.dropna(subset=['Bid']) #remove unmatched trades\n",
    "\n",
    "matchTQ_backward = matchTQ_backward.drop(matchTQ_backward[(matchTQ_backward['datetime'].dt.time < pd.Timestamp(\"09:30:00\").time()) |\n",
    "                (matchTQ_backward['datetime'].dt.time > pd.Timestamp(\"16:00:00\").time())].index) #regular trading hours\n",
    "\n",
    "matchTQ_backward = matchTQ_backward.drop(matchTQ_backward[(matchTQ_backward['datetime'].dt.time < pd.Timestamp(\"09:30:01\").time())].index) #delete first-second transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchTQ_backward['BidAskSpread'] = matchTQ_backward['Ask'] - matchTQ_backward['Bid']\n",
    "matchTQ_backward = matchTQ_backward.drop(matchTQ_backward[(matchTQ_backward['BidAskSpread'] <0)].index) #delete bid-ask spreads with negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchTQ_backward = matchTQ_backward.rename(columns={'Time_x': 'TradeTime', 'Time_y': 'QuoteTime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchTQ_backward = matchTQ_backward.drop(columns=['Bidvol', 'Askvol','datetime']) #remove unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchTQ_backward.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_file = os.path.join(os.getcwd(), \"cleaned_TAQ_IBM_N_2020_Feb_Mar_Apr_Thu.parquet\")\n",
    "matchTQ_backward.to_parquet(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
